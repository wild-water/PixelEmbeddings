{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our main computing device is 'cuda:0'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import tqdm\n",
    "\n",
    "def get_computing_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    return device\n",
    "\n",
    "device = get_computing_device()\n",
    "print(f\"Our main computing device is '{device}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(predictions, gt):\n",
    "    return F.binary_cross_entropy_with_logits(predictions, gt.float()).mean()\n",
    "\n",
    "def eval_model(model, data_generator):\n",
    "    accuracy = []\n",
    "    model.train(False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in tqdm.tqdm(data_generator):\n",
    "            X_batch = X_batch.to(device)\n",
    "            logits = torch.sigmoid(model(X_batch))\n",
    "            y_pred = logits.round().data\n",
    "            accuracy.append(np.mean((y_batch[:,11:12].cpu() == y_pred.cpu()).numpy()))\n",
    "            \n",
    "    return np.mean(accuracy)\n",
    "\n",
    "            \n",
    "def train_model(model, optimizer, train_data_generator):\n",
    "    train_loss = []\n",
    "    model.train(True)\n",
    "    i = 0\n",
    "    for (X_batch, y_batch) in tqdm.tqdm(train_data_generator):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device) \n",
    "        predictions = model(X_batch)\n",
    "        loss = compute_loss(predictions, y_batch[:,11:12])\n",
    "        loss.backward()\n",
    "        # backward\n",
    "        optimizer.step()\n",
    "\n",
    "        # metrics\n",
    "        train_loss.append(loss.cpu().data.numpy())\n",
    "        i += 1\n",
    "        if i > 100: break\n",
    "    return np.mean(train_loss)\n",
    "\n",
    "\n",
    "def train_loop(model, optimizer, train_data_generator, val_data_generator, num_epochs):\n",
    "    \"\"\"\n",
    "    num_epochs - total amount of full passes over training data\n",
    "    \"\"\"\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        train_loss = train_model(model, optimizer, train_data_generator)\n",
    "        \n",
    "        val_accuracy = eval_model(model, val_data_generator)\n",
    "\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss (in-iteration): \\t{:.6f}\".format(train_loss))\n",
    "        print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(val_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'celeba'\n",
    "\n",
    "class CropCelebA64:\n",
    "    \n",
    "    def __call__(self, pic):\n",
    "        new_pic = pic.crop((15, 40, 178 - 15, 218 - 30))\n",
    "        return new_pic\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '()'\n",
    "\n",
    "train_dataset = torchvision.datasets.CelebA(\n",
    "    root=root,\n",
    "    split='train',\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        CropCelebA64(),\n",
    "        torchvision.transforms.Resize(64),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.ToTensor()\n",
    "    ]),\n",
    ")\n",
    "\n",
    "validation_dataset = torchvision.datasets.CelebA(\n",
    "    root=root,\n",
    "    split='valid',\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        CropCelebA64(),\n",
    "        torchvision.transforms.Resize(64),\n",
    "        torchvision.transforms.ToTensor()\n",
    "    ]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "train_batch_gen = torch.utils.data.DataLoader(train_dataset, \n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=2)\n",
    "\n",
    "val_batch_gen = torch.utils.data.DataLoader(validation_dataset, \n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False,\n",
    "                                            num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet3plus import UNet3Plus\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, d=64, num_out=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(d, 128, 3, 2, 1)\n",
    "        self.pool = nn.MaxPool2d(32)\n",
    "        self.fc = nn.Linear(128, num_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        return self.fc(x)\n",
    "    \n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_channels=3, d=64, bilinear=True, feature_scale=4,\n",
    "                  is_deconv=True, is_batchnorm=True):\n",
    "        super().__init__()\n",
    "        self.encoder = UNet3Plus()\n",
    "        self.decoder = Decoder(d=d, num_out=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return self.decoder(x)\n",
    "    \n",
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 100/20347 [00:47<2:39:57,  2.11it/s]\n",
      "  4%|▍         | 100/2484 [00:10<04:19,  9.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 4 took 58.312s\n",
      "  training loss (in-iteration): \t0.455782\n",
      "  validation accuracy: \t\t\t75.50 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 100/20347 [00:47<2:40:14,  2.11it/s]\n",
      "  4%|▍         | 100/2484 [00:10<04:18,  9.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 of 4 took 58.341s\n",
      "  training loss (in-iteration): \t0.473256\n",
      "  validation accuracy: \t\t\t67.45 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 100/20347 [00:47<2:40:14,  2.11it/s]\n",
      "  4%|▍         | 100/2484 [00:10<04:20,  9.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 of 4 took 58.424s\n",
      "  training loss (in-iteration): \t0.440144\n",
      "  validation accuracy: \t\t\t75.50 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 100/20347 [00:47<2:40:57,  2.10it/s]\n",
      "  4%|▍         | 100/2484 [00:10<04:19,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 of 4 took 58.573s\n",
      "  training loss (in-iteration): \t0.484641\n",
      "  validation accuracy: \t\t\t75.50 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "train_loop(model, opt, train_batch_gen, val_batch_gen, num_epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
